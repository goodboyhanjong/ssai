{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Modules\n",
    "\n",
    "import pyrfc\n",
    "from configparser import ConfigParser as config\n",
    "import sys\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "from pyrfc import Connection\n",
    "from datetime import timedelta\n",
    "\n",
    "# Option Modules For Jupyter Notebook\n",
    "\n",
    "# from tqdm import tnrange, tqdm_notebook\n",
    "# from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import timeit\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "# pd.options.display.max_columns = 100\n",
    "# pd.options.display.max_rows = 100\n",
    "\n",
    "\n",
    "# SAP SERVER INFO.\n",
    "conn_string = \"host=192.168.198.120 dbname=postgres user=postgres password=seoul001!\"\n",
    "conn = psycopg2.connect(conn_string)\n",
    "psy_conn = psycopg2.connect(conn_string)\n",
    "cur = conn.cursor()\n",
    "# Postgres SERVER INFO.\n",
    "engine = create_engine(\"postgresql://postgres:seoul001!@192.168.198.120/postgres\") # set yours (postgres info.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = pd.read_sql_table('zzw1_anl_mst_samp_v1', engine, schema='ssai1')\n",
    "v2 = pd.read_sql_table('zzw1_anl_mst_samp_v2', engine, schema='ssai1')\n",
    "v3 = pd.read_sql_table('zzw1_anl_mst_samp_v3', engine, schema='ssai1')\n",
    "prod = pd.read_sql_table('zzw1_anl_mst_prod', engine, schema='ssai1')\n",
    "\n",
    "new_spl_goods_detail = pd.read_sql_table('new_spl_goods_detail', engine, schema='ssai1')\n",
    "mara = pd.read_sql_table('mara', engine, schema='ssai1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 3, 4, 17, 43, 36, 214221)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = datetime.now() - timedelta(days=1) # 어제날짜기준 today\n",
    "today = int(str(to)[:10].replace('-',''))\n",
    "# today = 202001114\n",
    "# TIME \n",
    "\n",
    "v1['ing_time'] = v1['proc_regi_date'].map(lambda x : today - int(str(x)[:10].replace('-','')))\n",
    "v2['ing_time'] = v2['proc_regi_date'].map(lambda x : today - int(str(x)[:10].replace('-','')))\n",
    "v3['ing_time'] = v3['proc_regi_date'].map(lambda x : today - int(str(x)[:10].replace('-','')))\n",
    "prod['ing_time'] = prod['erdat'].map(lambda x : today - int(str(x)[:10].replace('-','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIME_ONE_MONTH\n",
    "\n",
    "to_add = datetime.now() + timedelta(days=30)\n",
    "today_add_month = int(str(to)[:10].replace('-',''))\n",
    "\n",
    "v1['am1'] = v1['duedate'].map(lambda x :  int(str(x)[:10].replace('-','')) - today_add_month if x != None else x)\n",
    "v2['am1'] = v2['spl_req_date'].map(lambda x : int(str(x)[:10].replace('-','')) - today_add_month if x != None else x)\n",
    "v3['am1'] = v3['duedate'].map(lambda x :  int(str(x)[:10].replace('-','')) - today_add_month if x != None else x)\n",
    "prod['am1'] = prod['edatu'].map(lambda x :  int(str(x)[:10].replace('-','')) - today_add_month if x != None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = v1[v1.process_state == 'RUNNING']\n",
    "v2 = v2[v2.process_state == 'RUNNING']\n",
    "v3 = v3[v3.process_state == 'RUNNING']\n",
    "prod = prod[prod.prod_pop_yn == 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod['kwmeng'] = prod['kwmeng'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진행 중\n",
    "\n",
    "# v1\n",
    "tot_ing_v1_proc_cnt = len(v1[(v1.process_state == 'RUNNING')&(v1.ing_time >= 0)].drop_duplicates('doc_no'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2\n",
    "tot_ing_v2_proc_cnt = len(v2[(v2.process_state == 'RUNNING')&(v2.ing_time >= 0)].drop_duplicates('spl_req_no'))\n",
    "\n",
    "# v3\n",
    "tot_ing_v3_proc_cnt = len(v3[(v3.process_state == 'RUNNING')&(v3.ing_time >= 0)].drop_duplicates('doc_no'))\n",
    "\n",
    "# prod\n",
    "tot_ing_prod_so_cnt = len(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())].drop_duplicates(['vgbel','vgpos']))\n",
    "tot_ing_prod_kwmeng = prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())].drop_duplicates(['vgbel','vgpos'])['kwmeng'].sum()\n",
    "\n",
    "# 향후 1개월\n",
    "\n",
    "# v1\n",
    "tot_am1_v1_proc_cnt = len(v1[(v1.process_state == 'RUNNING')&(v1.am1 >= 0)&(v1.am1 >= 0)].drop_duplicates('doc_no'))\n",
    "\n",
    "# v2\n",
    "tot_am1_v2_proc_cnt = len(v2[(v2.process_state == 'RUNNING')&(v2.am1 >= 0)&(v2.am1 >= 0)].drop_duplicates('spl_req_no'))\n",
    "\n",
    "# v3\n",
    "tot_am1_v3_proc_cnt = len(v3[(v3.process_state == 'RUNNING')&(v3.am1 >= 0)&(v3.am1 >= 0)].drop_duplicates('doc_no'))\n",
    "\n",
    "# prod\n",
    "tot_am1_prod_so_cnt = len(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos']))\n",
    "tot_am1_prod_kwmeng = prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos'])['kwmeng'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = v1, v2, v3, prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_lst:\n",
    "    i['tot_ing_v1_proc_cnt'] = tot_ing_v1_proc_cnt\n",
    "    i['tot_ing_v2_proc_cnt'] = tot_ing_v2_proc_cnt\n",
    "    i['tot_ing_v3_proc_cnt'] = tot_ing_v3_proc_cnt\n",
    "    i['tot_ing_prod_so_cnt'] = tot_ing_prod_so_cnt\n",
    "    i['tot_ing_prod_kwmeng'] = tot_ing_prod_kwmeng\n",
    "    i['tot_am1_v1_proc_cnt'] = tot_am1_v1_proc_cnt\n",
    "    i['tot_am1_v2_proc_cnt'] = tot_am1_v2_proc_cnt\n",
    "    i['tot_am1_v3_proc_cnt'] = tot_am1_v3_proc_cnt\n",
    "    i['tot_am1_prod_so_cnt'] = tot_am1_prod_so_cnt\n",
    "    i['tot_am1_prod_kwmeng'] = tot_am1_prod_kwmeng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 사업군"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge table 1\n",
    "\n",
    "sector_ing_v1 = pd.DataFrame(v1[(v1.process_state == 'RUNNING')&(v1.ing_time >= 0)].drop_duplicates('doc_no').groupby('sector')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'sec_ing_v1_proc_cnt'})\n",
    "sector_ing_v2 = pd.DataFrame(v2[(v2.process_state == 'RUNNING')&(v2.ing_time >= 0)].drop_duplicates('spl_req_no').groupby('sector')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'sec_ing_v2_proc_cnt'})\n",
    "sector_ing_v3 = pd.DataFrame(v3[(v3.process_state == 'RUNNING')&(v3.ing_time >= 0)].drop_duplicates('doc_no').groupby('sector')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'sec_ing_v3_proc_cnt'})\n",
    "sector_ing_prod = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos']).groupby('sector')['pernr'].count()).reset_index().rename(columns = {'pernr':'sec_ing_prod_so_cnt'})\n",
    "sector_ing_prod2 = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())].drop_duplicates(['vgbel','vgpos']).groupby('sector')['kwmeng'].sum()).reset_index().rename(columns = {'kwmeng':'sec_ing_prod_kwmeng'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge table 2\n",
    "\n",
    "sector_am1_v1 = pd.DataFrame(v1[(v1.process_state == 'RUNNING')&(v1.am1 >= 0)&(v1.am1 >= 0)].drop_duplicates('doc_no').groupby('sector')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'sec_am1_v1_proc_cnt'})\n",
    "sector_am1_v2 = pd.DataFrame(v2[(v2.process_state == 'RUNNING')&(v2.am1 >= 0)&(v2.am1 >= 0)].drop_duplicates('spl_req_no').groupby('sector')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'sec_am1_v2_proc_cnt'})\n",
    "sector_am1_v3 = pd.DataFrame(v3[(v3.process_state == 'RUNNING')&(v3.am1 >= 0)&(v3.am1 >= 0)].drop_duplicates('doc_no').groupby('sector')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'sec_am1_v3_proc_cnt'})\n",
    "sector_am1_prod = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos'])).groupby('sector')['pernr'].count().reset_index().rename(columns = {'pernr':'sec_am1_prod_so_cnt'})\n",
    "sector_am1_prod2 = prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos']).groupby('sector')['kwmeng'].sum().reset_index().rename(columns = {'kwmeng':'sec_am1_prod_kwmeng'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## v1\n",
    "\n",
    "v1 = pd.merge(v1, sector_ing_v1, how='left', on='sector')\n",
    "v1 = pd.merge(v1, sector_am1_v1, how='left', on='sector')\n",
    "\n",
    "v1 = pd.merge(v1, sector_ing_v2, how='left', on='sector')\n",
    "v1 = pd.merge(v1, sector_am1_v2, how='left', on='sector')\n",
    "\n",
    "v1 = pd.merge(v1, sector_ing_v3, how='left', on='sector')\n",
    "v1 = pd.merge(v1, sector_am1_v3, how='left', on='sector')\n",
    "\n",
    "v1 = pd.merge(v1, sector_ing_prod, how='left', on='sector')\n",
    "v1 = pd.merge(v1, sector_ing_prod2, how='left', on='sector')\n",
    "\n",
    "v1 = pd.merge(v1, sector_am1_prod, how='left', on='sector')\n",
    "v1 = pd.merge(v1, sector_am1_prod2, how='left', on='sector')\n",
    "\n",
    "## v2\n",
    "\n",
    "v2 =  pd.merge(v2, sector_ing_v1, how='left', on='sector')\n",
    "v2 =  pd.merge(v2, sector_am1_v1, how='left', on='sector')\n",
    "\n",
    "v2 =  pd.merge(v2, sector_ing_v2, how='left', on='sector')\n",
    "v2 =  pd.merge(v2, sector_am1_v2, how='left', on='sector')\n",
    "\n",
    "v2 =  pd.merge(v2, sector_ing_v3, how='left', on='sector')\n",
    "v2 =  pd.merge(v2, sector_am1_v3, how='left', on='sector')\n",
    "\n",
    "v2 =  pd.merge(v2, sector_ing_prod, how='left', on='sector')\n",
    "v2 =  pd.merge(v2, sector_ing_prod2, how='left', on='sector')\n",
    "\n",
    "v2 =  pd.merge(v2, sector_am1_prod, how='left', on='sector')\n",
    "v2 =  pd.merge(v2, sector_am1_prod2, how='left', on='sector')\n",
    "\n",
    "## v3\n",
    "\n",
    "v3 = pd.merge(v3, sector_ing_v1, how='left', on='sector')\n",
    "v3 = pd.merge(v3, sector_am1_v1, how='left', on='sector')\n",
    "\n",
    "v3 = pd.merge(v3, sector_ing_v2, how='left', on='sector')\n",
    "v3 = pd.merge(v3, sector_am1_v2, how='left', on='sector')\n",
    "\n",
    "v3 = pd.merge(v3, sector_ing_v3, how='left', on='sector')\n",
    "v3 = pd.merge(v3, sector_am1_v3, how='left', on='sector')\n",
    "\n",
    "v3 = pd.merge(v3, sector_ing_prod, how='left', on='sector')\n",
    "v3 = pd.merge(v3, sector_ing_prod2, how='left', on='sector')\n",
    "\n",
    "v3 = pd.merge(v3, sector_am1_prod, how='left', on='sector')\n",
    "v3 = pd.merge(v3, sector_am1_prod2, how='left', on='sector')\n",
    "\n",
    "## v4\n",
    "\n",
    "prod = pd.merge(prod, sector_ing_v1, how='left', on='sector')\n",
    "prod = pd.merge(prod, sector_am1_v1, how='left', on='sector')\n",
    "\n",
    "prod = pd.merge(prod, sector_ing_v2, how='left', on='sector')\n",
    "prod = pd.merge(prod, sector_am1_v2, how='left', on='sector')\n",
    "\n",
    "prod = pd.merge(prod, sector_ing_v3, how='left', on='sector')\n",
    "prod = pd.merge(prod, sector_am1_v3, how='left', on='sector')\n",
    "\n",
    "prod = pd.merge(prod, sector_ing_prod, how='left', on='sector')\n",
    "prod = pd.merge(prod, sector_ing_prod2, how='left', on='sector')\n",
    "\n",
    "prod = pd.merge(prod, sector_am1_prod, how='left', on='sector')\n",
    "prod = pd.merge(prod, sector_am1_prod2, how='left', on='sector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 생산지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1['prod_bukrs'] = v1['prmn_emp_bukrs']\n",
    "v2['prod_bukrs'] = v2['dev_emp_bukrs']\n",
    "v3['prod_bukrs'] = v3['dev_emp_bukrs']\n",
    "prod['prod_bukrs'] = prod['werks_bukrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge table 1\n",
    "\n",
    "prod_ing_v1 = pd.DataFrame(v1[(v1.process_state == 'RUNNING')&(v1.ing_time >= 0)].drop_duplicates('doc_no').groupby('prod_bukrs')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'prod_ing_v1_proc_cnt'})\n",
    "prod_ing_v2 = pd.DataFrame(v2[(v2.process_state == 'RUNNING')&(v2.ing_time >= 0)].drop_duplicates('spl_req_no').groupby('prod_bukrs')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'prod_ing_v2_proc_cnt'})\n",
    "prod_ing_v3 = pd.DataFrame(v3[(v3.process_state == 'RUNNING')&(v3.ing_time >= 0)].drop_duplicates('doc_no').groupby('prod_bukrs')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'prod_ing_v3_proc_cnt'})\n",
    "prod_ing_prod = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos']).groupby('prod_bukrs')['pernr'].count()).reset_index().rename(columns = {'pernr':'prod_ing_prod_so_cnt'})\n",
    "prod_ing_prod2 = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())].drop_duplicates(['vgbel','vgpos']).groupby('prod_bukrs')['kwmeng'].sum()).reset_index().rename(columns = {'kwmeng':'prod_ing_prod_kwmeng'})\n",
    "\n",
    "# merge table 2\n",
    "\n",
    "prod_am1_v1 = pd.DataFrame(v1[(v1.process_state == 'RUNNING')&(v1.am1 >= 0)&(v1.am1 >= 0)].drop_duplicates('doc_no').groupby('prod_bukrs')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'prod_am1_v1_proc_cnt'})\n",
    "prod_am1_v2 = pd.DataFrame(v2[(v2.process_state == 'RUNNING')&(v2.am1 >= 0)&(v2.am1 >= 0)].drop_duplicates('spl_req_no').groupby('prod_bukrs')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'prod_am1_v2_proc_cnt'})\n",
    "prod_am1_v3 = pd.DataFrame(v3[(v3.process_state == 'RUNNING')&(v3.am1 >= 0)&(v3.am1 >= 0)].drop_duplicates('doc_no').groupby('prod_bukrs')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'prod_am1_v3_proc_cnt'})\n",
    "prod_am1_prod = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos'])).groupby('prod_bukrs')['pernr'].count().reset_index().rename(columns = {'pernr':'prod_am1_prod_so_cnt'})\n",
    "prod_am1_prod2 = prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos']).groupby('prod_bukrs')['kwmeng'].sum().reset_index().rename(columns = {'kwmeng':'prod_am1_prod_kwmeng'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## v1\n",
    "\n",
    "v1 = pd.merge(v1, prod_ing_v1, how='left', on='prod_bukrs')\n",
    "v1 = pd.merge(v1, prod_am1_v1, how='left', on='prod_bukrs')\n",
    "\n",
    "v1 = pd.merge(v1, prod_ing_v2, how='left', on='prod_bukrs')\n",
    "v1 = pd.merge(v1, prod_am1_v2, how='left', on='prod_bukrs')\n",
    "\n",
    "v1 = pd.merge(v1, prod_ing_v3, how='left', on='prod_bukrs')\n",
    "v1 = pd.merge(v1, prod_am1_v3, how='left', on='prod_bukrs')\n",
    "\n",
    "v1 = pd.merge(v1, prod_ing_prod, how='left', on='prod_bukrs')\n",
    "v1 = pd.merge(v1, prod_ing_prod2, how='left', on='prod_bukrs')\n",
    "\n",
    "v1 = pd.merge(v1, prod_am1_prod, how='left', on='prod_bukrs')\n",
    "v1 = pd.merge(v1, prod_am1_prod2, how='left', on='prod_bukrs')\n",
    "\n",
    "## v2\n",
    "\n",
    "v2 =  pd.merge(v2, prod_ing_v1, how='left', on='prod_bukrs')\n",
    "v2 =  pd.merge(v2, prod_am1_v1, how='left', on='prod_bukrs')\n",
    "\n",
    "v2 =  pd.merge(v2, prod_ing_v2, how='left', on='prod_bukrs')\n",
    "v2 =  pd.merge(v2, prod_am1_v2, how='left', on='prod_bukrs')\n",
    "\n",
    "v2 =  pd.merge(v2, prod_ing_v3, how='left', on='prod_bukrs')\n",
    "v2 =  pd.merge(v2, prod_am1_v3, how='left', on='prod_bukrs')\n",
    "\n",
    "v2 =  pd.merge(v2, prod_ing_prod, how='left', on='prod_bukrs')\n",
    "v2 =  pd.merge(v2, prod_ing_prod2, how='left', on='prod_bukrs')\n",
    "\n",
    "v2 =  pd.merge(v2, prod_am1_prod, how='left', on='prod_bukrs')\n",
    "v2 =  pd.merge(v2, prod_am1_prod2, how='left', on='prod_bukrs')\n",
    "\n",
    "## v3\n",
    "\n",
    "v3 = pd.merge(v3, prod_ing_v1, how='left', on='prod_bukrs')\n",
    "v3 = pd.merge(v3, prod_am1_v1, how='left', on='prod_bukrs')\n",
    "\n",
    "v3 = pd.merge(v3, prod_ing_v2, how='left', on='prod_bukrs')\n",
    "v3 = pd.merge(v3, prod_am1_v2, how='left', on='prod_bukrs')\n",
    "\n",
    "v3 = pd.merge(v3, prod_ing_v3, how='left', on='prod_bukrs')\n",
    "v3 = pd.merge(v3, prod_am1_v3, how='left', on='prod_bukrs')\n",
    "\n",
    "v3 = pd.merge(v3, prod_ing_prod, how='left', on='prod_bukrs')\n",
    "v3 = pd.merge(v3, prod_ing_prod2, how='left', on='prod_bukrs')\n",
    "\n",
    "v3 = pd.merge(v3, prod_am1_prod, how='left', on='prod_bukrs')\n",
    "v3 = pd.merge(v3, prod_am1_prod2, how='left', on='prod_bukrs')\n",
    "\n",
    "## v4\n",
    "\n",
    "prod = pd.merge(prod, prod_ing_v1, how='left', on='prod_bukrs')\n",
    "prod = pd.merge(prod, prod_am1_v1, how='left', on='prod_bukrs')\n",
    "\n",
    "prod = pd.merge(prod, prod_ing_v2, how='left', on='prod_bukrs')\n",
    "prod = pd.merge(prod, prod_am1_v2, how='left', on='prod_bukrs')\n",
    "\n",
    "prod = pd.merge(prod, prod_ing_v3, how='left', on='prod_bukrs')\n",
    "prod = pd.merge(prod, prod_am1_v3, how='left', on='prod_bukrs')\n",
    "\n",
    "\n",
    "prod = pd.merge(prod, prod_ing_prod, how='left', on='prod_bukrs')\n",
    "prod = pd.merge(prod, prod_ing_prod2, how='left', on='prod_bukrs')\n",
    "\n",
    "prod = pd.merge(prod, prod_am1_prod, how='left', on='prod_bukrs')\n",
    "prod = pd.merge(prod, prod_am1_prod2, how='left', on='prod_bukrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 제품코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_spl_goods_detail['item_code'] = new_spl_goods_detail['item_code'].map(lambda x : x.lstrip('0') if x != None else x)\n",
    "mara['matnr'] = mara['matnr'].map(lambda x : x.lstrip('0') if x != None else x)\n",
    "new_spl_goods_detail = pd.merge(new_spl_goods_detail, mara[['matnr','spart']], how='left', left_on='item_code',right_on='matnr')\n",
    "v1 = pd.merge(v1, new_spl_goods_detail[['doc_no','item_code','spart']], how='left', on='doc_no')\n",
    "prod['item_code'] = prod['matnr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge table 1\n",
    "\n",
    "item_ing_v1 = pd.DataFrame(v1[(v1.process_state == 'RUNNING')&(v1.ing_time >= 0)].drop_duplicates('doc_no').groupby('item_code')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'item_ing_v1_proc_cnt'})\n",
    "item_ing_v2 = pd.DataFrame(v2[(v2.process_state == 'RUNNING')&(v2.ing_time >= 0)].drop_duplicates('spl_req_no').groupby('item_code')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'item_ing_v2_proc_cnt'})\n",
    "item_ing_v3 = pd.DataFrame(v3[(v3.process_state == 'RUNNING')&(v3.ing_time >= 0)].drop_duplicates('doc_no').groupby('item_code')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'item_ing_v3_proc_cnt'})\n",
    "item_ing_prod = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos']).groupby('item_code')['pernr'].count()).reset_index().rename(columns = {'pernr':'item_ing_prod_so_cnt'})\n",
    "item_ing_prod2 = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())].drop_duplicates(['vgbel','vgpos']).groupby('item_code')['kwmeng'].sum()).reset_index().rename(columns = {'kwmeng':'item_ing_prod_kwmeng'})\n",
    "\n",
    "# merge table 2\n",
    "\n",
    "item_am1_v1 = pd.DataFrame(v1[(v1.process_state == 'RUNNING')&(v1.am1 >= 0)&(v1.am1 >= 0)].drop_duplicates('doc_no').groupby('item_code')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'item_am1_v1_proc_cnt'})\n",
    "item_am1_v2 = pd.DataFrame(v2[(v2.process_state == 'RUNNING')&(v2.am1 >= 0)&(v2.am1 >= 0)].drop_duplicates('spl_req_no').groupby('item_code')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'item_am1_v2_proc_cnt'})\n",
    "item_am1_v3 = pd.DataFrame(v3[(v3.process_state == 'RUNNING')&(v3.am1 >= 0)&(v3.am1 >= 0)].drop_duplicates('doc_no').groupby('item_code')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'item_am1_v3_proc_cnt'})\n",
    "item_am1_prod = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos'])).groupby('item_code')['pernr'].count().reset_index().rename(columns = {'pernr':'item_am1_prod_so_cnt'})\n",
    "item_am1_prod2 = prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos']).groupby('item_code')['kwmeng'].sum().reset_index().rename(columns = {'kwmeng':'item_am1_prod_kwmeng'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## v1\n",
    "\n",
    "v1 = pd.merge(v1, item_ing_v1, how='left', on='item_code')\n",
    "v1 = pd.merge(v1, item_am1_v1, how='left', on='item_code')\n",
    "\n",
    "v1 = pd.merge(v1, item_ing_v2, how='left', on='item_code')\n",
    "v1 = pd.merge(v1, item_am1_v2, how='left', on='item_code')\n",
    "\n",
    "v1 = pd.merge(v1, item_ing_v3, how='left', on='item_code')\n",
    "v1 = pd.merge(v1, item_am1_v3, how='left', on='item_code')\n",
    "\n",
    "v1 = pd.merge(v1, item_ing_prod, how='left', on='item_code')\n",
    "v1 = pd.merge(v1, item_ing_prod2, how='left', on='item_code')\n",
    "\n",
    "v1 = pd.merge(v1, item_am1_prod, how='left', on='item_code')\n",
    "v1 = pd.merge(v1, item_am1_prod2, how='left', on='item_code')\n",
    "\n",
    "## v2\n",
    "\n",
    "v2 =  pd.merge(v2, item_ing_v1, how='left', on='item_code')\n",
    "v2 =  pd.merge(v2, item_am1_v1, how='left', on='item_code')\n",
    "\n",
    "v2 =  pd.merge(v2, item_ing_v2, how='left', on='item_code')\n",
    "v2 =  pd.merge(v2, item_am1_v2, how='left', on='item_code')\n",
    "\n",
    "v2 =  pd.merge(v2, item_ing_v3, how='left', on='item_code')\n",
    "v2 =  pd.merge(v2, item_am1_v3, how='left', on='item_code')\n",
    "\n",
    "v2 =  pd.merge(v2, item_ing_prod, how='left', on='item_code')\n",
    "v2 =  pd.merge(v2, item_ing_prod2, how='left', on='item_code')\n",
    "\n",
    "v2 =  pd.merge(v2, item_am1_prod, how='left', on='item_code')\n",
    "v2 =  pd.merge(v2, item_am1_prod2, how='left', on='item_code')\n",
    "\n",
    "## v3\n",
    "\n",
    "v3 = pd.merge(v3, item_ing_v1, how='left', on='item_code')\n",
    "v3 = pd.merge(v3, item_am1_v1, how='left', on='item_code')\n",
    "\n",
    "v3 = pd.merge(v3, item_ing_v2, how='left', on='item_code')\n",
    "v3 = pd.merge(v3, item_am1_v2, how='left', on='item_code')\n",
    "\n",
    "v3 = pd.merge(v3, item_ing_v3, how='left', on='item_code')\n",
    "v3 = pd.merge(v3, item_am1_v3, how='left', on='item_code')\n",
    "\n",
    "v3 = pd.merge(v3, item_ing_prod, how='left', on='item_code')\n",
    "v3 = pd.merge(v3, item_ing_prod2, how='left', on='item_code')\n",
    "\n",
    "v3 = pd.merge(v3, item_am1_prod, how='left', on='item_code')\n",
    "v3 = pd.merge(v3, item_am1_prod2, how='left', on='item_code')\n",
    "\n",
    "## v4\n",
    "\n",
    "prod = pd.merge(prod, item_ing_v1, how='left', on='item_code')\n",
    "prod = pd.merge(prod, item_am1_v1, how='left', on='item_code')\n",
    "\n",
    "prod = pd.merge(prod, item_ing_v2, how='left', on='item_code')\n",
    "prod = pd.merge(prod, item_am1_v2, how='left', on='item_code')\n",
    "\n",
    "prod = pd.merge(prod, item_ing_v3, how='left', on='item_code')\n",
    "prod = pd.merge(prod, item_am1_v3, how='left', on='item_code')\n",
    "\n",
    "prod = pd.merge(prod, item_ing_prod, how='left', on='item_code')\n",
    "prod = pd.merge(prod, item_ing_prod2, how='left', on='item_code')\n",
    "\n",
    "prod = pd.merge(prod, item_am1_prod, how='left', on='item_code')\n",
    "prod = pd.merge(prod, item_am1_prod2, how='left', on='item_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 제품군"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge table 1\n",
    "\n",
    "spart_ing_v1 = pd.DataFrame(v1[(v1.process_state == 'RUNNING')&(v1.ing_time >= 0)].drop_duplicates('doc_no').groupby('spart')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'spart_ing_v1_proc_cnt'})\n",
    "spart_ing_v2 = pd.DataFrame(v2[(v2.process_state == 'RUNNING')&(v2.ing_time >= 0)].drop_duplicates('spl_req_no').groupby('spart')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'spart_ing_v2_proc_cnt'})\n",
    "spart_ing_v3 = pd.DataFrame(v3[(v3.process_state == 'RUNNING')&(v3.ing_time >= 0)].drop_duplicates('doc_no').groupby('spart')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'spart_ing_v3_proc_cnt'})\n",
    "spart_ing_prod = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos']).groupby('spart')['pernr'].count()).reset_index().rename(columns = {'pernr':'spart_ing_prod_so_cnt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spart_ing_prod2 = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())].drop_duplicates(['vgbel','vgpos']).groupby('spart')['kwmeng'].sum()).reset_index().rename(columns = {'kwmeng':'spart_ing_prod_kwmeng'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge table 2\n",
    "\n",
    "spart_am1_v1 = pd.DataFrame(v1[(v1.process_state == 'RUNNING')&(v1.am1 >= 0)&(v1.am1 >= 0)].drop_duplicates('doc_no').groupby('spart')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'spart_am1_v1_proc_cnt'})\n",
    "spart_am1_v2 = pd.DataFrame(v2[(v2.process_state == 'RUNNING')&(v2.am1 >= 0)&(v2.am1 >= 0)].drop_duplicates('spl_req_no').groupby('spart')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'spart_am1_v2_proc_cnt'})\n",
    "spart_am1_v3 = pd.DataFrame(v3[(v3.process_state == 'RUNNING')&(v3.am1 >= 0)&(v3.am1 >= 0)].drop_duplicates('doc_no').groupby('spart')['sale_emp_no'].count()).reset_index().rename(columns = {'sale_emp_no':'spart_am1_v3_proc_cnt'})\n",
    "spart_am1_prod = pd.DataFrame(prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos'])).groupby('spart')['pernr'].count().reset_index().rename(columns = {'pernr':'spart_am1_prod_so_cnt'})\n",
    "spart_am1_prod2 = prod[(prod.prod_pop_yn == 'Y')&(prod.ing_time >= 0)&(prod.max_wadat_ist.notnull())&(prod.am1 >= 0)].drop_duplicates(['vgbel','vgpos']).groupby('spart')['kwmeng'].sum().reset_index().rename(columns = {'kwmeng':'spart_am1_prod_kwmeng'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## v1\n",
    "\n",
    "v1 = pd.merge(v1, spart_ing_v1, how='left', on='spart')\n",
    "v1 = pd.merge(v1, spart_am1_v1, how='left', on='spart')\n",
    "\n",
    "v1 = pd.merge(v1, spart_ing_v2, how='left', on='spart')\n",
    "v1 = pd.merge(v1, spart_am1_v2, how='left', on='spart')\n",
    "\n",
    "v1 = pd.merge(v1, spart_ing_v3, how='left', on='spart')\n",
    "v1 = pd.merge(v1, spart_am1_v3, how='left', on='spart')\n",
    "\n",
    "v1 = pd.merge(v1, spart_ing_prod, how='left', on='spart')\n",
    "v1 = pd.merge(v1, spart_ing_prod2, how='left', on='spart')\n",
    "\n",
    "v1 = pd.merge(v1, spart_am1_prod, how='left', on='spart')\n",
    "v1 = pd.merge(v1, spart_am1_prod2, how='left', on='spart')\n",
    "\n",
    "## v2\n",
    "\n",
    "v2 =  pd.merge(v2, spart_ing_v1, how='left', on='spart')\n",
    "v2 =  pd.merge(v2, spart_am1_v1, how='left', on='spart')\n",
    "\n",
    "v2 =  pd.merge(v2, spart_ing_v2, how='left', on='spart')\n",
    "v2 =  pd.merge(v2, spart_am1_v2, how='left', on='spart')\n",
    "\n",
    "v2 =  pd.merge(v2, spart_ing_v3, how='left', on='spart')\n",
    "v2 =  pd.merge(v2, spart_am1_v3, how='left', on='spart')\n",
    "\n",
    "v2 =  pd.merge(v2, spart_ing_prod, how='left', on='spart')\n",
    "v2 =  pd.merge(v2, spart_ing_prod2, how='left', on='spart')\n",
    "\n",
    "v2 =  pd.merge(v2, spart_am1_prod, how='left', on='spart')\n",
    "v2 =  pd.merge(v2, spart_am1_prod2, how='left', on='spart')\n",
    "\n",
    "## v3\n",
    "\n",
    "v3 = pd.merge(v3, spart_ing_v1, how='left', on='spart')\n",
    "v3 = pd.merge(v3, spart_am1_v1, how='left', on='spart')\n",
    "\n",
    "v3 = pd.merge(v3, spart_ing_v2, how='left', on='spart')\n",
    "v3 = pd.merge(v3, spart_am1_v2, how='left', on='spart')\n",
    "\n",
    "v3 = pd.merge(v3, spart_ing_v3, how='left', on='spart')\n",
    "v3 = pd.merge(v3, spart_am1_v3, how='left', on='spart')\n",
    "\n",
    "v3 = pd.merge(v3, spart_ing_prod, how='left', on='spart')\n",
    "v3 = pd.merge(v3, spart_ing_prod2, how='left', on='spart')\n",
    "\n",
    "v3 = pd.merge(v3, spart_am1_prod, how='left', on='spart')\n",
    "v3 = pd.merge(v3, spart_am1_prod2, how='left', on='spart')\n",
    "\n",
    "## v4\n",
    "\n",
    "prod = pd.merge(prod, spart_ing_v1, how='left', on='spart')\n",
    "prod = pd.merge(prod, spart_am1_v1, how='left', on='spart')\n",
    "\n",
    "prod = pd.merge(prod, spart_ing_v2, how='left', on='spart')\n",
    "prod = pd.merge(prod, spart_am1_v2, how='left', on='spart')\n",
    "\n",
    "prod = pd.merge(prod, spart_ing_v3, how='left', on='spart')\n",
    "prod = pd.merge(prod, spart_am1_v3, how='left', on='spart')\n",
    "\n",
    "prod = pd.merge(prod, spart_ing_prod, how='left', on='spart')\n",
    "prod = pd.merge(prod, spart_ing_prod2, how='left', on='spart')\n",
    "\n",
    "prod = pd.merge(prod, spart_am1_prod, how='left', on='spart')\n",
    "prod = pd.merge(prod, spart_am1_prod2, how='left', on='spart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1[['spl_regi_date','duedate']] = v1[['spl_regi_date','duedate']].applymap(lambda x : datetime(int(x[:4]),int(x[4:6]),int(x[6:])) if x != None else x)\n",
    "v1['req_worst_days'] = v1['duedate'] - v1['spl_regi_date'] + timedelta(days=1)\n",
    "\n",
    "v2[['spl_req_date','req_date']] = v2[['spl_req_date','req_date']].applymap(lambda x : datetime(int(x[:4]),int(x[4:6]),int(x[6:])) if x != None else x)\n",
    "v2['req_worst_days'] = v2['spl_req_date'] - v2['req_date'] + timedelta(days=1)\n",
    "\n",
    "v3[['duedate','req_date']] = v3[['duedate','req_date']].applymap(lambda x : datetime(int(x[:4]),int(x[4:6]),int(x[6:])) if x != None else x)\n",
    "v3['req_worst_days'] = v3['duedate'] - v3['req_date'] + timedelta(days=1)\n",
    "\n",
    "prod[['edatu','erdat']] = prod[['edatu','erdat']].applymap(lambda x : datetime(int(x[:4]),int(x[4:6]),int(x[6:])) if x != None else x)\n",
    "prod['req_worst_days'] = prod['edatu'] - prod['erdat'] + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1['train_test_cls'] = 'OPERATION'\n",
    "fin_v1 = v1[[\n",
    "\n",
    "'sale_emp_no',\n",
    "'sale_emp_name',\n",
    "'sale_dept_code',\n",
    "'sale_dept_name',\n",
    "'cust_code',\n",
    "'cust_name',\n",
    "'doc_no',\n",
    "'spl_regi_date',\n",
    "'regi_emp_no',\n",
    "'duedate',\n",
    "'p_level',\n",
    "'distri_chan',\n",
    "'sales_group',\n",
    "'state',\n",
    "'file_id',\n",
    "'saup_gubn',\n",
    "'sales_office',\n",
    "'sales_orga',\n",
    "'sales_group_name',\n",
    "'po_no',\n",
    "'uses_code',\n",
    "'uses',\n",
    "'so_no',\n",
    "'numbering_yn',\n",
    "'extent_yn',\n",
    "'semi_yn',\n",
    "'use_import_yn',\n",
    "'prmn_emp_no',\n",
    "'prmn_emp_bukrs',\n",
    "'process_id',\n",
    "'process_name',\n",
    "'process_state',\n",
    "'proc_regi_date',\n",
    "'proc_updt_date',\n",
    "'proc_finished_date',\n",
    "'doc_title',\n",
    "'exit_cmt',\n",
    "'wid',\n",
    "'activity_id',\n",
    "'activity_name',\n",
    "'next_activity_id',\n",
    "'activity_state',\n",
    "'act_regi_date',\n",
    "'act_updt_date',\n",
    "'act_finished_date',\n",
    "'selected_date',\n",
    "'first_selected_date',\n",
    "'usrid4',\n",
    "'gbdat',\n",
    "'zpos',\n",
    "'zpos2',\n",
    "'persg',\n",
    "'begda',\n",
    "'endda',\n",
    "'aedat',\n",
    "'bukrs',\n",
    "'usrtyp',\n",
    "'persk',\n",
    "'zpos3',\n",
    "'zsjob',\n",
    "'age',\n",
    "'work_years',\n",
    "'rank',\n",
    "'land1',\n",
    "'ktokd',\n",
    "'niels',\n",
    "'j_1kfrepre',\n",
    "'j_1kftbus',\n",
    "'j_1kftind',\n",
    "'sector',\n",
    "'req_worst_days',\n",
    "'tot_ing_v1_proc_cnt',\n",
    "'tot_ing_v2_proc_cnt',\n",
    "'tot_ing_v3_proc_cnt',\n",
    "'tot_ing_prod_so_cnt',\n",
    "'tot_ing_prod_kwmeng',\n",
    "'tot_am1_v1_proc_cnt',\n",
    "'tot_am1_v2_proc_cnt',\n",
    "'tot_am1_v3_proc_cnt',\n",
    "'tot_am1_prod_so_cnt',\n",
    "'tot_am1_prod_kwmeng',\n",
    "'sec_ing_v1_proc_cnt',\n",
    "'sec_ing_v2_proc_cnt',\n",
    "'sec_ing_v3_proc_cnt',\n",
    "'sec_ing_prod_so_cnt',\n",
    "'sec_ing_prod_kwmeng',\n",
    "'sec_am1_v1_proc_cnt',\n",
    "'sec_am1_v2_proc_cnt',\n",
    "'sec_am1_v3_proc_cnt',\n",
    "'sec_am1_prod_so_cnt',\n",
    "'sec_am1_prod_kwmeng',\n",
    "'prod_ing_v1_proc_cnt',\n",
    "'prod_ing_v2_proc_cnt',\n",
    "'prod_ing_v3_proc_cnt',\n",
    "'prod_ing_prod_so_cnt',\n",
    "'prod_ing_prod_kwmeng',\n",
    "'prod_am1_v1_proc_cnt',\n",
    "'prod_am1_v2_proc_cnt',\n",
    "'prod_am1_v3_proc_cnt',\n",
    "'prod_am1_prod_so_cnt',\n",
    "'prod_am1_prod_kwmeng',\n",
    "'item_ing_v1_proc_cnt',\n",
    "'item_ing_v2_proc_cnt',\n",
    "'item_ing_v3_proc_cnt',\n",
    "'item_ing_prod_so_cnt',\n",
    "'item_ing_prod_kwmeng',\n",
    "'item_am1_v1_proc_cnt',\n",
    "'item_am1_v2_proc_cnt',\n",
    "'item_am1_v3_proc_cnt',\n",
    "'item_am1_prod_so_cnt',\n",
    "'item_am1_prod_kwmeng',\n",
    "'spart_ing_v1_proc_cnt',\n",
    "'spart_ing_v2_proc_cnt',\n",
    "'spart_ing_v3_proc_cnt',\n",
    "'spart_ing_prod_so_cnt',\n",
    "'spart_ing_prod_kwmeng',\n",
    "'spart_am1_v1_proc_cnt',\n",
    "'spart_am1_v2_proc_cnt',\n",
    "'spart_am1_v3_proc_cnt',\n",
    "'spart_am1_prod_so_cnt',\n",
    "'spart_am1_prod_kwmeng',\n",
    "'train_test_cls',\n",
    "'req_worst_days',\n",
    "\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2['train_test_cls'] = 'OPERATION'\n",
    "fin_v2 = v2[[\n",
    "\n",
    "'sale_emp_no',\n",
    "'sale_emp_name',\n",
    "'sale_dept_code',\n",
    "'sale_dept_name',\n",
    "'cust_code',\n",
    "'cust_name',\n",
    "'spl_req_no',\n",
    "'req_date',\n",
    "'req_emp_no',\n",
    "'req_dept_code',\n",
    "'saup_gubn',\n",
    "'spl_req_date',\n",
    "'project_id',\n",
    "'project_name',\n",
    "'dev_gubn',\n",
    "'req_gubn',\n",
    "'item_name',\n",
    "'uses',\n",
    "'spl_gubn',\n",
    "'spl_qty',\n",
    "'exp_unit',\n",
    "'month_exp_qty',\n",
    "'month_exp_amt',\n",
    "'year_exp_qty',\n",
    "'year_exp_amt',\n",
    "'prod_exp_date',\n",
    "'spec_gubn',\n",
    "'spl_amt_gubn',\n",
    "'state',\n",
    "'prod_date',\n",
    "'spl_conf_date',\n",
    "'spl_conf_qty',\n",
    "'item_code',\n",
    "'ship_date',\n",
    "'spl_unit',\n",
    "'make_amt',\n",
    "'currency',\n",
    "'exchange',\n",
    "'urgency_gubun',\n",
    "'uses_code',\n",
    "'client',\n",
    "'company_code',\n",
    "'category_group',\n",
    "'category_code',\n",
    "'category_text',\n",
    "'unit_price',\n",
    "'sample_type',\n",
    "'shipment_completion_date',\n",
    "'item_order',\n",
    "'local_yn',\n",
    "'fb_emp_no',\n",
    "'sample_type_detail',\n",
    "'crm_pjt_code',\n",
    "'crm_pjt_name',\n",
    "'module_yn',\n",
    "'dev_emp_no',\n",
    "'dev_emp_bukrs',\n",
    "'pid',\n",
    "'process_id',\n",
    "'process_name',\n",
    "'process_state',\n",
    "'proc_regi_date',\n",
    "'proc_updt_date',\n",
    "'proc_finished_date',\n",
    "'doc_title',\n",
    "'exit_cmt',\n",
    "'wid',\n",
    "'activity_id',\n",
    "'activity_name',\n",
    "'next_activity_id',\n",
    "'activity_state',\n",
    "'act_regi_date',\n",
    "'act_updt_date',\n",
    "'act_finished_date',\n",
    "'selected_date',\n",
    "'first_selected_date',\n",
    "'rank',\n",
    "'usrid4',\n",
    "'gbdat',\n",
    "'zpos',\n",
    "'zpos2',\n",
    "'persg',\n",
    "'begda',\n",
    "'endda',\n",
    "'aedat',\n",
    "'bukrs',\n",
    "'usrtyp',\n",
    "'persk',\n",
    "'zpos3',\n",
    "'zsjob',\n",
    "'age',\n",
    "'work_years',\n",
    "'land1',\n",
    "'sector',\n",
    "'ersda',\n",
    "'laeda',\n",
    "'mtart',\n",
    "'mbrsh',\n",
    "'matkl',\n",
    "'meins',\n",
    "'tragr',\n",
    "'spart',\n",
    "'mtpos_mara',\n",
    "'req_worst_days',\n",
    "'tot_ing_v1_proc_cnt',\n",
    "'tot_ing_v2_proc_cnt',\n",
    "'tot_ing_v3_proc_cnt',\n",
    "'tot_ing_prod_so_cnt',\n",
    "'tot_ing_prod_kwmeng',\n",
    "'tot_am1_v1_proc_cnt',\n",
    "'tot_am1_v2_proc_cnt',\n",
    "'tot_am1_v3_proc_cnt',\n",
    "'tot_am1_prod_so_cnt',\n",
    "'tot_am1_prod_kwmeng',\n",
    "'sec_ing_v1_proc_cnt',\n",
    "'sec_ing_v2_proc_cnt',\n",
    "'sec_ing_v3_proc_cnt',\n",
    "'sec_ing_prod_so_cnt',\n",
    "'sec_ing_prod_kwmeng',\n",
    "'sec_am1_v1_proc_cnt',\n",
    "'sec_am1_v2_proc_cnt',\n",
    "'sec_am1_v3_proc_cnt',\n",
    "'sec_am1_prod_so_cnt',\n",
    "'sec_am1_prod_kwmeng',\n",
    "'prod_ing_v1_proc_cnt',\n",
    "'prod_ing_v2_proc_cnt',\n",
    "'prod_ing_v3_proc_cnt',\n",
    "'prod_ing_prod_so_cnt',\n",
    "'prod_ing_prod_kwmeng',\n",
    "'prod_am1_v1_proc_cnt',\n",
    "'prod_am1_v2_proc_cnt',\n",
    "'prod_am1_v3_proc_cnt',\n",
    "'prod_am1_prod_so_cnt',\n",
    "'prod_am1_prod_kwmeng',\n",
    "'item_ing_v1_proc_cnt',\n",
    "'item_ing_v2_proc_cnt',\n",
    "'item_ing_v3_proc_cnt',\n",
    "'item_ing_prod_so_cnt',\n",
    "'item_ing_prod_kwmeng',\n",
    "'item_am1_v1_proc_cnt',\n",
    "'item_am1_v2_proc_cnt',\n",
    "'item_am1_v3_proc_cnt',\n",
    "'item_am1_prod_so_cnt',\n",
    "'item_am1_prod_kwmeng',\n",
    "'spart_ing_v1_proc_cnt',\n",
    "'spart_ing_v2_proc_cnt',\n",
    "'spart_ing_v3_proc_cnt',\n",
    "'spart_ing_prod_so_cnt',\n",
    "'spart_ing_prod_kwmeng',\n",
    "'spart_am1_v1_proc_cnt',\n",
    "'spart_am1_v2_proc_cnt',\n",
    "'spart_am1_v3_proc_cnt',\n",
    "'spart_am1_prod_so_cnt',\n",
    "'spart_am1_prod_kwmeng',\n",
    "'train_test_cls',\n",
    "\n",
    "\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3['train_test_cls'] = 'OPERATION'\n",
    "fin_v3 = v3[[\n",
    "    \n",
    "'sale_emp_no',\n",
    "'sale_emp_name',\n",
    "'sale_dept_code',\n",
    "'sale_dept_name',\n",
    "'cust_code',\n",
    "'cust_name',\n",
    "'doc_no',\n",
    "'req_date',\n",
    "'req_emp_no',\n",
    "'req_dept_code',\n",
    "'req_saup_gubn',\n",
    "'duedate',\n",
    "'plm_project_id',\n",
    "'plm_project_name',\n",
    "'crm_pjt_code',\n",
    "'crm_pjt_name',\n",
    "'dev_gubn',\n",
    "'req_gubn',\n",
    "'cust_saup_gubn',\n",
    "'crm_cust_code',\n",
    "'crm_cust_name',\n",
    "'dev_item_name',\n",
    "'item_code',\n",
    "'item_name',\n",
    "'prod_exp_date',\n",
    "'spl_gubn',\n",
    "'spl_amt_gubn',\n",
    "'sales_group',\n",
    "'sales_group_name',\n",
    "'sales_office',\n",
    "'sales_orga',\n",
    "'cie',\n",
    "'flux',\n",
    "'intensity',\n",
    "'voltage',\n",
    "'end_customer_code',\n",
    "'end_customer',\n",
    "'sales_center',\n",
    "'distri_chan',\n",
    "'exp_unit',\n",
    "'currency',\n",
    "'spl_qty',\n",
    "'exchange',\n",
    "'month_exp_qty',\n",
    "'month_exp_amt',\n",
    "'year_exp_qty',\n",
    "'year_exp_amt',\n",
    "'dev_dept',\n",
    "'spec_gubn',\n",
    "'local_yn',\n",
    "'sample_type',\n",
    "'category_code',\n",
    "'category_group',\n",
    "'category_text',\n",
    "'company_code',\n",
    "'unit_price',\n",
    "'module_yn',\n",
    "'production_code',\n",
    "'packing_type',\n",
    "'so_no',\n",
    "'stock_hold_gubn',\n",
    "'orgin_stock_qty',\n",
    "'stock_qty',\n",
    "'dev_part_ship_yn',\n",
    "'ship_done_qty',\n",
    "'feedback_date',\n",
    "'shipment_completion_date',\n",
    "'kms_yn',\n",
    "'kms_pkg_item_code',\n",
    "'kms_pkg_item_name',\n",
    "'kms_pkg_req_qty',\n",
    "'dev_emp_no',\n",
    "'dev_emp_bukrs',\n",
    "'pid',\n",
    "'process_id',\n",
    "'process_name',\n",
    "'process_state',\n",
    "'proc_regi_date',\n",
    "'proc_updt_date',\n",
    "'proc_finished_date',\n",
    "'doc_title',\n",
    "'exit_cmt',\n",
    "'wid',\n",
    "'activity_id',\n",
    "'activity_name',\n",
    "'next_activity_id',\n",
    "'activity_state',\n",
    "'act_regi_date',\n",
    "'act_updt_date',\n",
    "'act_finished_date',\n",
    "'selected_date',\n",
    "'first_selected_date',\n",
    "'rank',\n",
    "'usrid4',\n",
    "'gbdat',\n",
    "'zpos',\n",
    "'zpos2',\n",
    "'persg',\n",
    "'begda',\n",
    "'endda',\n",
    "'aedat',\n",
    "'bukrs',\n",
    "'usrtyp',\n",
    "'persk',\n",
    "'zpos3',\n",
    "'zsjob',\n",
    "'age',\n",
    "'work_years',\n",
    "'land1',\n",
    "'ktokd',\n",
    "'niels',\n",
    "'j_1kfrepre',\n",
    "'j_1kftbus',\n",
    "'j_1kftind',\n",
    "'sector',\n",
    "'ersda',\n",
    "'laeda',\n",
    "'mtart',\n",
    "'mbrsh',\n",
    "'matkl',\n",
    "'meins',\n",
    "'tragr',\n",
    "'spart',\n",
    "'mtpos_mara',\n",
    "'req_worst_days',\n",
    "'tot_ing_v1_proc_cnt',\n",
    "'tot_ing_v2_proc_cnt',\n",
    "'tot_ing_v3_proc_cnt',\n",
    "'tot_ing_prod_so_cnt',\n",
    "'tot_ing_prod_kwmeng',\n",
    "'tot_am1_v1_proc_cnt',\n",
    "'tot_am1_v2_proc_cnt',\n",
    "'tot_am1_v3_proc_cnt',\n",
    "'tot_am1_prod_so_cnt',\n",
    "'tot_am1_prod_kwmeng',\n",
    "'sec_ing_v1_proc_cnt',\n",
    "'sec_ing_v2_proc_cnt',\n",
    "'sec_ing_v3_proc_cnt',\n",
    "'sec_ing_prod_so_cnt',\n",
    "'sec_ing_prod_kwmeng',\n",
    "'sec_am1_v1_proc_cnt',\n",
    "'sec_am1_v2_proc_cnt',\n",
    "'sec_am1_v3_proc_cnt',\n",
    "'sec_am1_prod_so_cnt',\n",
    "'sec_am1_prod_kwmeng',\n",
    "'prod_ing_v1_proc_cnt',\n",
    "'prod_ing_v2_proc_cnt',\n",
    "'prod_ing_v3_proc_cnt',\n",
    "'prod_ing_prod_so_cnt',\n",
    "'prod_ing_prod_kwmeng',\n",
    "'prod_am1_v1_proc_cnt',\n",
    "'prod_am1_v2_proc_cnt',\n",
    "'prod_am1_v3_proc_cnt',\n",
    "'prod_am1_prod_so_cnt',\n",
    "'prod_am1_prod_kwmeng',\n",
    "'item_ing_v1_proc_cnt',\n",
    "'item_ing_v2_proc_cnt',\n",
    "'item_ing_v3_proc_cnt',\n",
    "'item_ing_prod_so_cnt',\n",
    "'item_ing_prod_kwmeng',\n",
    "'item_am1_v1_proc_cnt',\n",
    "'item_am1_v2_proc_cnt',\n",
    "'item_am1_v3_proc_cnt',\n",
    "'item_am1_prod_so_cnt',\n",
    "'item_am1_prod_kwmeng',\n",
    "'spart_ing_v1_proc_cnt',\n",
    "'spart_ing_v2_proc_cnt',\n",
    "'spart_ing_v3_proc_cnt',\n",
    "'spart_ing_prod_so_cnt',\n",
    "'spart_ing_prod_kwmeng',\n",
    "'spart_am1_v1_proc_cnt',\n",
    "'spart_am1_v2_proc_cnt',\n",
    "'spart_am1_v3_proc_cnt',\n",
    "'spart_am1_prod_so_cnt',\n",
    "'spart_am1_prod_kwmeng',\n",
    "'train_test_cls',\n",
    "    \n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = prod.rename(columns={'zdatu2_max':'zdatu2'})\n",
    "prod['train_test_cls'] = 'OPERATION'\n",
    "\n",
    "fin_prod = prod[[\n",
    "\n",
    "'pernr',\n",
    "'snamek',\n",
    "'orgeh',\n",
    "'orgtx',\n",
    "'kunnr',\n",
    "'name1',\n",
    "'bstkd',\n",
    "'vgbel',\n",
    "'vgpos',\n",
    "'matnr',\n",
    "'maktx',\n",
    "'spart',\n",
    "'edatu',\n",
    "'erdat',\n",
    "'zdatu2',\n",
    "'zdatu2_adj',\n",
    "'kwmeng',\n",
    "'auart',\n",
    "'bezei',\n",
    "'vtweg',\n",
    "'pvtext',\n",
    "'vkbur',\n",
    "'sabezei',\n",
    "'vkgrp',\n",
    "'sgbezei',\n",
    "'vkorg',\n",
    "'vtext',\n",
    "'werks',\n",
    "'dispo',\n",
    "'dsnam',\n",
    "'werks_bukrs',\n",
    "'zpltrz',\n",
    "'vbeln_cnt',\n",
    "'sum_lfimg',\n",
    "'max_wadat_ist',\n",
    "'first_wadat_ist',\n",
    "'gstrp',\n",
    "'first_gstrp',\n",
    "'gamng',\n",
    "'budat',\n",
    "'first_budat',\n",
    "'erfmg',\n",
    "'usrid4',\n",
    "'gbdat',\n",
    "'zpos',\n",
    "'zpos2',\n",
    "'persg',\n",
    "'begda',\n",
    "'endda',\n",
    "'aedat',\n",
    "'bukrs',\n",
    "'usrtyp',\n",
    "'persk',\n",
    "'zpos3',\n",
    "'zsjob',\n",
    "'age',\n",
    "'work_years',\n",
    "'land1',\n",
    "'ktokd',\n",
    "'niels',\n",
    "'j_1kfrepre',\n",
    "'j_1kftbus',\n",
    "'j_1kftind',\n",
    "'sector',\n",
    "'ersda',\n",
    "'laeda',\n",
    "'mtart',\n",
    "'mbrsh',\n",
    "'matkl',\n",
    "'meins',\n",
    "'tragr',\n",
    "'zdatu0',\n",
    "'mara_spart',\n",
    "'mtpos_mara',\n",
    "'dev_sample_yn',\n",
    "'prod_pop_yn',\n",
    "'req_worst_days',\n",
    "'tot_ing_v1_proc_cnt',\n",
    "'tot_ing_v2_proc_cnt',\n",
    "'tot_ing_v3_proc_cnt',\n",
    "'tot_ing_prod_so_cnt',\n",
    "'tot_ing_prod_kwmeng',\n",
    "'tot_am1_v1_proc_cnt',\n",
    "'tot_am1_v2_proc_cnt',\n",
    "'tot_am1_v3_proc_cnt',\n",
    "'tot_am1_prod_so_cnt',\n",
    "'tot_am1_prod_kwmeng',\n",
    "'sec_ing_v1_proc_cnt',\n",
    "'sec_ing_v2_proc_cnt',\n",
    "'sec_ing_v3_proc_cnt',\n",
    "'sec_ing_prod_so_cnt',\n",
    "'sec_ing_prod_kwmeng',\n",
    "'sec_am1_v1_proc_cnt',\n",
    "'sec_am1_v2_proc_cnt',\n",
    "'sec_am1_v3_proc_cnt',\n",
    "'sec_am1_prod_so_cnt',\n",
    "'sec_am1_prod_kwmeng',\n",
    "'prod_ing_v1_proc_cnt',\n",
    "'prod_ing_v2_proc_cnt',\n",
    "'prod_ing_v3_proc_cnt',\n",
    "'prod_ing_prod_so_cnt',\n",
    "'prod_ing_prod_kwmeng',\n",
    "'prod_am1_v1_proc_cnt',\n",
    "'prod_am1_v2_proc_cnt',\n",
    "'prod_am1_v3_proc_cnt',\n",
    "'prod_am1_prod_so_cnt',\n",
    "'prod_am1_prod_kwmeng',\n",
    "'item_ing_v1_proc_cnt',\n",
    "'item_ing_v2_proc_cnt',\n",
    "'item_ing_v3_proc_cnt',\n",
    "'item_ing_prod_so_cnt',\n",
    "'item_ing_prod_kwmeng',\n",
    "'item_am1_v1_proc_cnt',\n",
    "'item_am1_v2_proc_cnt',\n",
    "'item_am1_v3_proc_cnt',\n",
    "'item_am1_prod_so_cnt',\n",
    "'item_am1_prod_kwmeng',\n",
    "'spart_ing_v1_proc_cnt',\n",
    "'spart_ing_v2_proc_cnt',\n",
    "'spart_ing_v3_proc_cnt',\n",
    "'spart_ing_prod_so_cnt',\n",
    "'spart_ing_prod_kwmeng',\n",
    "'spart_am1_v1_proc_cnt',\n",
    "'spart_am1_v2_proc_cnt',\n",
    "'spart_am1_v3_proc_cnt',\n",
    "'spart_am1_prod_so_cnt',\n",
    "'spart_am1_prod_kwmeng',\n",
    "'train_test_cls',\n",
    "\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 현재 진행 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_date = datetime.now() + timedelta(days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "fin_v1['act_finished_date'] = fin_v1['act_finished_date'].map(lambda x : fill_date if str(x) == 'NaT' else x)\n",
    "\n",
    "fin_v1['act_finished_date'] = fin_v1['act_finished_date'].map(lambda x : str(x)[:19].replace('-',''))\n",
    "fin_v1['act_finished_date'] = fin_v1['act_finished_date'].map(lambda x : str(x)[:19].replace(' ',''))\n",
    "fin_v1['act_finished_date'] = fin_v1['act_finished_date'].map(lambda x : str(x)[:19].replace(':',''))\n",
    "\n",
    "fin_v1['act_finished_date'] = fin_v1['act_finished_date'].astype(int)\n",
    "\n",
    "fin_v1 = fin_v1.sort_values(['doc_no','act_finished_date']).drop_duplicates('doc_no', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "fin_v2['act_finished_date'] = fin_v2['act_finished_date'].map(lambda x : fill_date if str(x) == 'NaT' else x)\n",
    "\n",
    "fin_v2['act_finished_date'] = fin_v2['act_finished_date'].map(lambda x : str(x)[:19].replace('-',''))\n",
    "fin_v2['act_finished_date'] = fin_v2['act_finished_date'].map(lambda x : str(x)[:19].replace(' ',''))\n",
    "fin_v2['act_finished_date'] = fin_v2['act_finished_date'].map(lambda x : str(x)[:19].replace(':',''))\n",
    "\n",
    "fin_v2['act_finished_date'] = fin_v2['act_finished_date'].astype(int)\n",
    "\n",
    "fin_v2 = fin_v2.sort_values(['spl_req_no','act_finished_date']).drop_duplicates('spl_req_no', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "fin_v3['act_finished_date'] = fin_v3['act_finished_date'].map(lambda x : fill_date if x == None else x)\n",
    "fin_v3['act_finished_date'] = fin_v3['act_finished_date'].map(lambda x : fill_date if str(x) == 'NaT' else x)\n",
    "\n",
    "fin_v3['act_finished_date'] = fin_v3['act_finished_date'].map(lambda x : str(x)[:19].replace('-',''))\n",
    "fin_v3['act_finished_date'] = fin_v3['act_finished_date'].map(lambda x : str(x)[:19].replace(' ',''))\n",
    "fin_v3['act_finished_date'] = fin_v3['act_finished_date'].map(lambda x : str(x)[:19].replace(':',''))\n",
    "\n",
    "fin_v3['act_finished_date'] = fin_v3['act_finished_date'].astype(int)\n",
    "\n",
    "fin_v3 = fin_v3.sort_values(['doc_no','act_finished_date']).drop_duplicates('doc_no', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "fin_prod['endda'] = fin_prod['endda'].map(lambda x : fill_date if x == None else x)\n",
    "\n",
    "fin_prod['endda'] = fin_prod['endda'].map(lambda x : str(x)[:19].replace('-',''))\n",
    "fin_prod['endda'] = fin_prod['endda'].map(lambda x : str(x)[:19].replace(' ',''))\n",
    "fin_prod['endda'] = fin_prod['endda'].map(lambda x : str(x)[:19].replace(':',''))\n",
    "\n",
    "fin_prod['endda'] = fin_prod['endda'].astype(int)\n",
    "\n",
    "fin_prod = fin_prod.sort_values(['vgbel','vgpos','endda']).drop_duplicates(['vgbel','vgpos'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zzw1_oper_mst_v1 = fin_v1\n",
    "zzw1_oper_mst_v2 = fin_v2\n",
    "zzw1_oper_mst_v3 = fin_v3\n",
    "zzw1_oper_mst_prod = fin_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['zzw1_oper_mst_v1','zzw1_oper_mst_v2','zzw1_oper_mst_v3','zzw1_oper_mst_prod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "zzw1_oper_mst_v1 = zzw1_oper_mst_v1.reset_index()\n",
    "zzw1_oper_mst_v2 = zzw1_oper_mst_v2.reset_index()\n",
    "zzw1_oper_mst_v3 = zzw1_oper_mst_v3.reset_index()\n",
    "zzw1_oper_mst_prod = zzw1_oper_mst_prod.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP PREVIOUS TABLE zzw1_oper_mst_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/ssai/lib/python3.6/site-packages/pandas/core/generic.py:2663: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  method=method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zzw1_oper_mst_v1 COMPLETE\n",
      "DROP PREVIOUS TABLE zzw1_oper_mst_v2\n",
      "zzw1_oper_mst_v2 COMPLETE\n",
      "DROP PREVIOUS TABLE zzw1_oper_mst_v3\n",
      "zzw1_oper_mst_v3 COMPLETE\n",
      "DROP PREVIOUS TABLE zzw1_oper_mst_prod\n",
      "zzw1_oper_mst_prod COMPLETE\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(conn_string)\n",
    "conn.autocommit = True  \n",
    "cur = conn.cursor()\n",
    "\n",
    "for v, tab in enumerate(lst):\n",
    "    \n",
    "    df = globals()[tab]\n",
    "    \n",
    "    try:\n",
    "        cur.execute('drop table ssai1.' + lst[v])\n",
    "        print('DROP PREVIOUS TABLE ' + lst[v])\n",
    "\n",
    "    except:\n",
    "        print('EMPTY TABLE ' + lst[v] +  ' IN POSTGRES')\n",
    "        pass\n",
    "    \n",
    "    df.to_sql(name = lst[v], # 테이블명 소문자로\n",
    "        con = engine, if_exists = 'append', index = False, schema = 'ssai1', method='multi', chunksize = 10000)\n",
    "    \n",
    "    print(lst[v] + ' COMPLETE')\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
